# ml-chess
Using PyTorch to compensate for my bad chess. An undocumented mess, oops!

I started this project a year(s?) ago and then left it hanging. It does contain a working chess engine (at least it used to... on my machine!) and I do recall playing against it. In complex middle games the engine would often out manuever me. Near the endgame it would struggle and fail. This is because the engine is good at evaluating static positions but only performes a few move rollout with simple Minimax.

This repo contains SPAGHETTI CODE from me messing around with PyTorch and chess algorithms. In this project, I use PyTorch to train various models to mimic stockfish evaluations. `ResNetEvaluator()` in `ChessPositionEvaluator.py` is not appropriately named, the current version looks to be using a simple convolution encoder and a linear decoder, no skip layers.

Here is the layout of the repo to the best of my memory:
 - `ChessPositionEvaluator.py` is for training models
 - `chess_utils.py` is for generating training data. The training data is board states with score labels generated by a UCI-compliant engine (Stockfish in this case.)
 - `board_utils.py` helper functions, testing; `get_bitboards()` is used to convert chess game states into tensors for PyTorch.
 - `main.py` facilitates playing actual games using the ML-evaluation engine + Minimax as well as using other engines.
 - `ResNet.py` and `ResNetEvaluator.py` have been excluded because I'm not sure if I ever used them for training chess evaluator models.
